{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8704960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260000\n",
      "260000\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "#https://s3.amazonaws.com/fast-ai-nlp/amazon_review_full_csv.tgz\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "df = pd.read_csv('/home/marivishnu/PC/NLTK/Product Reviews/amazon_review_full_csv/test.csv')\n",
    "\n",
    "positive = []\n",
    "negative = []\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, \"rating\"] >= 4:\n",
    "        positive.append(word_tokenize(str(df.loc[i, 'review2'])))\n",
    "    if df.loc[i, \"rating\"] <= 2:\n",
    "        negative.append(word_tokenize(str(df.loc[i, 'review2'])))\n",
    "print(len(positive)) #260000\n",
    "print(len(negative)) #260000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2ec634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def clean(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stopwords_set = stopwords.words('english')\n",
    "    \n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords_set and word not in string.punctuation:\n",
    "            clean_words.append(lemmatizer.lemmatize(word))\n",
    "    dict_words = dict([word, True] for word in clean_words)\n",
    "    return dict_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a096dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260000\n",
      "260000\n",
      "({'fast': True, 'read': True, 'filled': True, 'unexpected': True, 'humour': True, 'profound': True, 'insight': True, 'art': True, 'politics': True, 'policy': True, 'brief': True, 'sly': True, 'wry': True, 'wise': True}, 'pos')\n",
      "({'model': True, 'may': True, 'ok': True, 'sedentary': True, 'type': True, \"'m\": True, 'active': True, 'get': True, 'around': True, 'alot': True, 'job': True, 'consistently': True, 'found': True, 'stocking': True, 'rolled': True, 'ankle': True, 'good': True, 'solution': True, 'go': True, 'standard': True, 'compression': True, '20-30': True, 'stock': True, '114622': True, 'excellent': True, 'support': True, 'stay': True, 'give': True, 'need': True, 'pair': True, 'also': True, 'tore': True, 'struggled': True, 'pull': True, 'time': True, 'riddance/bad': True, 'investment': True}, 'neg')\n"
     ]
    }
   ],
   "source": [
    "pos_set = []\n",
    "for review in positive:\n",
    "    pos_set.append((clean(review), 'pos'))\n",
    "neg_set = []\n",
    "for review in negative:\n",
    "    neg_set.append((clean(review), 'neg'))\n",
    "\n",
    "print(len(pos_set))\n",
    "print(len(neg_set))\n",
    "print(pos_set[0])\n",
    "print(neg_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e86e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4520dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416000\n",
      "104000\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(pos_set)\n",
    "shuffle(neg_set)\n",
    "\n",
    "train_set = pos_set[:208000] + neg_set[:208000]\n",
    "test_set = pos_set[208000:] + neg_set[208000:]\n",
    "\n",
    "print(len(train_set)) #416000\n",
    "print(len(test_set))  #104000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "746151a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.06634615384615\n"
     ]
    }
   ],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d53f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = []\n",
    "for review in test_set:\n",
    "    reference.append(review[1])\n",
    "test = []\n",
    "for review in test_set:\n",
    "    test.append(classifier.classify(review[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7caec61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104000\n",
      "104000\n"
     ]
    }
   ],
   "source": [
    "print(len(reference))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2d145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     n     p |\n",
      "    |     e     o |\n",
      "    |     g     s |\n",
      "----+-------------+\n",
      "neg |<47562> 4438 |\n",
      "pos | 17333<34667>|\n",
      "----+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "label\tprecision\trecall\tf_measure\n",
      "neg\t0.7329070036212343\t0.9146538461538462\t0.813755934813294\n",
      "pos\t0.8865106763840941\t0.6666730769230769\t0.7610339717907907\n",
      "Accuracy =  79.06634615384615\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import *\n",
    "print(ConfusionMatrix(reference, test))\n",
    "CM = ConfusionMatrix(reference, test)\n",
    "\n",
    "labels = {'pos', 'neg'}\n",
    "\n",
    "from collections import Counter\n",
    "TP, FN, FP = Counter(), Counter(), Counter()\n",
    "for i in labels:\n",
    "    for j in labels:\n",
    "        if i == j:\n",
    "            TP[i] += int(CM[i,j])\n",
    "        else:\n",
    "            FN[i] += int(CM[i,j])\n",
    "            FP[j] += int(CM[i,j])\n",
    "\n",
    "print(\"label\\tprecision\\trecall\\tf_measure\")\n",
    "for label in sorted(labels):\n",
    "    precision, recall = 0, 0\n",
    "    if TP[label] == 0:\n",
    "        f_measure = 0\n",
    "    else:\n",
    "        precision = float(TP[label]) / (TP[label]+FP[label])\n",
    "        recall = float(TP[label]) / (TP[label]+FN[label])\n",
    "        f_measure = float(2) * (precision * recall) / (precision + recall)\n",
    "    print(label+\"\\t\"+str(precision)+\"\\t\"+str(recall)+\"\\t\"+str(f_measure))\n",
    "    \n",
    "print(\"Accuracy = \",accuracy(reference, test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7a5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Laptop speed is very slow, hanging issue. \n",
      " -> neg\n",
      "\n",
      " The product fits as expected. It is comfortable to wear and does not degrade after washing. It is made of good quality cotton material which ensures that it can be worn in summer without feeling warm. Overall a good quality product given the price  -> pos\n"
     ]
    }
   ],
   "source": [
    "review = '''\n",
    "  Laptop speed is very slow, hanging issue. \n",
    "'''\n",
    "tokenized = word_tokenize(review)\n",
    "cleaned = clean(tokenized)\n",
    "print(review, '->', classifier.classify(cleaned))\n",
    "\n",
    "review = '''\n",
    " The product fits as expected. It is comfortable to wear and does not degrade after washing. It is made of good quality cotton material which ensures that it can be worn in summer without feeling warm. Overall a good quality product given the price '''\n",
    "tokenized = word_tokenize(review)\n",
    "cleaned = clean(tokenized)\n",
    "print(review, '->', classifier.classify(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45d5f836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              restocking = True              neg : pos    =     35.9 : 1.0\n",
      "         unsubstantiated = True              neg : pos    =     30.3 : 1.0\n",
      "                  refund = True              neg : pos    =     29.0 : 1.0\n",
      "               illegible = True              neg : pos    =     28.3 : 1.0\n",
      "              inoperable = True              neg : pos    =     27.0 : 1.0\n",
      "                   tripe = True              neg : pos    =     25.4 : 1.0\n",
      "                unevenly = True              neg : pos    =     24.4 : 1.0\n",
      "              pleasently = True              pos : neg    =     23.0 : 1.0\n",
      "           uninteresting = True              neg : pos    =     22.6 : 1.0\n",
      "               refunding = True              neg : pos    =     21.4 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (classifier.show_most_informative_features(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
